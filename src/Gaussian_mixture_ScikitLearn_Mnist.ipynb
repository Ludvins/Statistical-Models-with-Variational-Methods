{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from inferpy.data import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "# seed\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare Mnist database form InferPy's package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from InferPy\n",
    "(X, y), _ = mnist.load_data(num_instances=1000, digits=[1,4,7])\n",
    "# Create dataframe\n",
    "dataset = pd.DataFrame(data=X)\n",
    "dataset[\"number\"] = y\n",
    "# Split dataframe\n",
    "X = dataset.drop(['number'], axis=1)\n",
    "y = dataset['number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ammount of samples\n",
    "n_samples = X.shape[0]\n",
    "# Observed space dimensionality\n",
    "data_dim = X.shape[1]\n",
    "# Ammount of classes\n",
    "n_classes = len(y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `BayesianGaussianMixture` object from [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html), with a number of components equal to the ammount of classes.\n",
    "\n",
    "The parameter `weight_concentration_prior_type` models if a Dirichlet distribution or a Dirichlet Process is used for the weights. In this case, we model using a distribution. \n",
    "\n",
    "The following prior values are used:\n",
    "- The means variable $\\mu$ follows a centered normal distribution: \n",
    "  $$\\mu_k \\sim \\mathcal{N}_{data\\_dim}(0,I).$$\n",
    "- The precision variables $\\Lambda$ follow a Wishart distribution with parameters\n",
    "  $$\\Lambda_k \\sim \\mathcal{W}_{data\\_dim}(data\\_dim, I).$$\n",
    "- The weights concentration variable follows a dirichlet with parameter\n",
    "  $$ \\pi \\sim \\text{Symmetric-Dirichlet}\\Big(\\frac{1}{n\\_classes}\\Big).$$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = BayesianGaussianMixture(n_components = n_classes, \n",
    "                             weight_concentration_prior_type = 'dirichlet_distribution',\n",
    "                             weight_concentration_prior = 1/n_classes,\n",
    "                             mean_precision_prior = 1,\n",
    "                             mean_prior = np.zeros([data_dim]),\n",
    "                             degrees_of_freedom_prior = data_dim,\n",
    "                             covariance_prior = np.identity(data_dim),\n",
    "                             max_iter = 1000,\n",
    "                             tol = 1e-3,\n",
    "                             random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model. The stop criteria is either reaching `max_iter` steps on the EM algorithm or having a lower bound difference betweeen iterations below `tol`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianGaussianMixture(covariance_prior=array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]]),\n",
       "                        degrees_of_freedom_prior=784, max_iter=1000,\n",
       "                        mean_precision_prior=1,\n",
       "                        mean_prior=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0....\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.]),\n",
       "                        n_components=3, random_state=0,\n",
       "                        weight_concentration_prior=0.3333333333333333,\n",
       "                        weight_concentration_prior_type='dirichlet_distribution')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most probable label for each datapoint is calculated using `predict`, we might calculate the acurated estimations as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.339\n"
     ]
    }
   ],
   "source": [
    "print(sum(gm.predict(X) == y)/n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's posterior parameters might be inspected via `weights_`, `means_` and `precisions_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26806527 0.38994339 0.34199134]\n"
     ]
    }
   ],
   "source": [
    "print(gm.weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(gm.means_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1051.71813954    0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.         1051.71813954    0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.         1051.71813954 ...    0.\n",
      "      0.            0.        ]\n",
      "  ...\n",
      "  [   0.            0.            0.         ... 1051.71813954\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "   1051.71813954    0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.         1051.71813954]]\n",
      "\n",
      " [[1173.5423185     0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.         1173.5423185     0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.         1173.5423185  ...    0.\n",
      "      0.            0.        ]\n",
      "  ...\n",
      "  [   0.            0.            0.         ... 1173.5423185\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "   1173.5423185     0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.         1173.5423185 ]]\n",
      "\n",
      " [[1125.61503966    0.            0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.         1125.61503966    0.         ...    0.\n",
      "      0.            0.        ]\n",
      "  [   0.            0.         1125.61503966 ...    0.\n",
      "      0.            0.        ]\n",
      "  ...\n",
      "  [   0.            0.            0.         ... 1125.61503966\n",
      "      0.            0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "   1125.61503966    0.        ]\n",
      "  [   0.            0.            0.         ...    0.\n",
      "      0.         1125.61503966]]]\n"
     ]
    }
   ],
   "source": [
    "print(gm.precisions_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG py3.6",
   "language": "python",
   "name": "tfg-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
