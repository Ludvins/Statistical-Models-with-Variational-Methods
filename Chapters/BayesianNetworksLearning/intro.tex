
In this chapter we are focusing on Bayesian Learning training, both Bayesian and Variational inference are considered. Firstly, the network structure is assumed and no hidden variables are considered. As all variables are visible, we are denoting \(\D\) the set of observations and \(\theta\) the set of parameters of the distributions.

The goal now is to determine the posterior \(P(\theta \mid \D)\) using a prior belief \(P(\theta)\) and the likelihood function \(P(\D \mid \theta)\),
\[
  P(\theta \mid  \D) = \frac{P(\D  \mid  \theta)P(\theta)}{P(\D)}.
\]

We are using the following example to illustrate the situation, in it we will try to learn the bias of a coin, given a set of tossing results.

\begin{exampleth}\label{ex:coin_toss}
  Let \(\D = \{d_n\}_{n \in 1,\dots,N}\) be the results of tossing a coin \(N \in
  \mathbb{N}\) times, let \(1\) symbolize \emph{heads} and \(0\) \emph{tails}.

  Our objective is to estimate the probability \(\theta\) that the coin will be
  head \(P(d_n = 1  \mid  \theta)\), for this we have the i.i.d random variables \(d_1,\dots,d_n\)
  and \(\theta\), and we require a model \(P(d_1,\dots,d_n,\theta)\). We have a
  Belief Network shown in figure~\ref{fig:learning_coin}
  \[
    P(\D,\theta) = P(\theta)\prod_{n=1}^N P(d_n \mid \theta).
  \]

\begin{figure}[h!]
\centering
\begin{tikzpicture}[
  node distance=1cm and 0.5cm,
  mynode/.style={draw,circle,text width=0.5cm,align=center}
]

\node[mynode] (a) {\(\theta\)};
\node[mynode, below=of a] (b) {\(d_n\)};
\plate{} {(b)} {\(n=1,dots,N\)}; %
\path (a) edge[-latex] (b)
;

\end{tikzpicture}
\caption{Belief network for coin tossing}
\label{fig:learning_coin}
\end{figure}

We want to calculate
\[
  P(\theta \mid \D) = \frac{P(\D \mid \theta)P(\theta)}{P(\D)},
\]
to do so, we need to specify the prior \(P(\theta)\), we are using a discrete
model where
\[
  P(\theta = 0.2) = 0.1, \quad P(\theta = 0.5) = 0.7 \quad \text{and} \quad P(\theta = 0.8) = 0.2.
\]
This means that we have a \(70\%\) belief that the coin is fair, a \(10\%\)
belied that is biased to tails and \(20\%\) that is biased to heads.
The parameter models the probability of a datapoint as
\[
  P(d_n = 1 \mid \theta) = \theta \quad \text{and} \quad P(d_n = 0 \mid \theta) = 1 - \theta .
  \] 

Let \(n_h\) be the number of heads in our observed data and \(n_t\)
the number of tails
\[
  n_{h} = \#\{d= 1\} \hspace{2cm} n_{t} = \#\{d = 0\},
\]

then the posterior has the form
\[
  P(\theta  \mid \D) = \frac{P(\theta)}{P(\D)} \theta^{n_h}(1-\theta)^{n_t}.
\]

Suppose that \(n_h = 2\) and \(n_t = 8\), then
\[
\begin{aligned}
  P(\theta = 0.2  \mid  \D) &= \frac{1}{P(\D)}\times 0.1 \times 0.2^{2}
  \times 0.8^{8} = \frac{1}{P(\D)} \times 6.71\times10^{-4}, \\
   P(\theta = 0.5  \mid  \D) &= \frac{1}{P(\D)}\times 0.7 \times 0.5^{2}
   \times 0.5^{8} = \frac{1}{P(\D)} \times 6.83\times10^{-4},\\
    P(\theta = 0.8  \mid  \D) &= \frac{1}{P(\D)}\times 0.2 \times 0.2^{2}
  \times 0.8^{8} = \frac{1}{P(\D)} \times 3.27\times10^{-7}.
\end{aligned}
\]

Now, we can compute
\[
   \frac{1}{P(\D)} =  6.71\times10^{-4} +   6.83\times10^{-4} +
   3.27\times10^{-7} = 0.00135.
 \]
Therefore, the posterior is
\[
\begin{aligned}
  P(\theta = 0.2  \mid  \D) &= 0.4979,\\
  P(\theta = 0.5  \mid  \D) &= 0.5059,\\
  P(\theta = 0.8  \mid  \D) &= 0.00024.
\end{aligned}
\]

These are the posterior parameter beliefs of our experiment. Given this, it we
were to choose a single value for the posterior it would be \(\theta = 0.5\), as it is the one with the highest probability.

This result is intuitive, we had a strong belief of the coin being fair
and even though the number of tails was quite bigger than heads, it
was not enough to make the difference. Obviously the posterior of the coin being
biased to tails is now bigger than the prior.

In this example, we have used a discrete prior for the parameter, a continouos prior may be chosen insted. Suppose an uniform prior distribution so that \(P(\theta) = k \implies \int_0^1 P(\theta) d\theta
= k = 1\) due to normalization.

Using the previous calculations we have
\[
  P(\theta \mid  \D) = \frac{1}{P(\D)} \theta^{n_h}(1-\theta)^{n_t},
\]
where
\[
  P(\D) = \int_0^1 \theta^{n_h}(1-\theta)^{n_t} d\theta.
\]
This implies that
\[
  P(\theta \mid \D) = \frac{\theta^{n_h}(1-\theta)^{n_t} }{ \int_0^1 u^{n_h}(1-u)^{n_t} du} \implies \theta \mid \D \sim Beta(n_h + 1, n_t + 1).
\]
\end{exampleth}

A Beta distribution may be also considered as the prior distribution:
\[
  \theta \sim \text{Beta}(\alpha, \beta) \implies P(\theta) = \frac{1}{B(\alpha, \beta)}\theta^{\alpha - 1}(1 - \theta)^{\beta - 1}.
\]
then, repeating the same as before we get that
\[
  P(\theta, \D) = \frac{1}{B(\alpha + n_h, \beta + n_t)}\theta^{\alpha
    + n_h - 1}(1 - \theta)^{\beta + n_t - 1} \implies (\theta, \D) \sim Beta(\alpha + n_h, \beta + n_t)
\]
\begin{remark}
  We have shown that the Beta distribution (prior and posterior) is conjugate of the Binomial distribution (likelihood).
\end{remark}

\section{Utility}
The Bayesian posterior says nothing about how to benefit from the beliefs it
represents, in order to do this we need to specify the utility of each decision.

With this idea we define an utility function over the parameters
\[
  U(\theta, \theta_{true}) = \alpha \mathbb{I}[\theta = \theta_{true}] - \beta
  \mathbb{I}[\theta \neq \theta_{true}],
\]
where \(\alpha, \beta \in \R\). This symbolizes the gains or looses of choosing
the parameter \(\theta\), when the true value of the parameter is supposed to be
\(\theta_{true}\). Therefore, the expected utility of a parameter \(\theta_0\) is
calculated as
\[
  U(\theta = \theta_0) = \sum_{\theta_{true}}U(\theta = \theta_0,
  \theta_{true})P(\theta = \theta_{true}  \mid  \D).
\]

We might as well define an utility function over the previous example:
\[
  U(\theta, \theta_{true}) = 10\mathbb{I}[\theta = \theta_{true}] - 20
  \mathbb{I}[\theta \neq \theta_{true}],
\]
where we interpret that the loss of choosing the wrong parameter is twice as
important as the gains from doing it right.

The expected utility of the decision that the parameter is \(\theta = 0.2\)
in our discrete example would be
\[
  \begin{aligned}
  U(\theta = 0.2) &= U(\theta = 0.2, \theta_{true} = 0.2)P(\theta_{true} = 0.2  \mid
  \D)\\
  &+ U(\theta = 0.2, \theta_{true} = 0.5)P(\theta_{true} = 0.5  \mid
  \D) \\
  & +  U(\theta = 0.2, \theta_{true} = 0.8)P(\theta_{true} = 0.8  \mid  \D)\\
  &= 10 \times 0.4979 - 20\times 0.5059 -20 \times 0.00024 \\
  &= -5.1438,\\
  U(\theta = 0.5) &= -4.9038, \\
  U(\theta = 0.8) &= -20.0736.
\end{aligned}
\]

