

In this section some concepts concerning probability
distributions among with some of the most used ones are summarized.

From now on, let \(X\) be a random variable and \(P\) its probability distribution.

\begin{definition}
  The \emph{mode} \(X_*\) of the probability distribution \(P\) is the state
  of \(X\) where the distribution takes it's highest value
  \[
    X_* = \argmax_x P(x).
  \]
A distribution could have more than one mode, in this case we say it is \emph{multi-modal}.
\end{definition}

\begin{definition}
  The notation \(\E{}{X}\) is used to denote the \emph{average} or
  \emph{expectation} of the values a real-valued variable takes respect to its
  distribution. It is worth mentioning that it might not exists.
  If \(X\) is non-negative, it is defined as
  \[
    \E{}{X} = \int_{\Omega} X(\omega)dP(\omega) \footnote{\(P\) is a
      measure over \(\Omega\)}.
  \]
  For a general variable \(X\), it is defined as \(\E{}{X} = \E{}{X^+} -
  \E{}{X^-}\). Where
  \[
    X^+(\omega) = \max(X(\omega), 0) \quad \text{and} \quad X^-(\omega) = \min(X(\omega), 0).
  \]

  In case the variable is continuous, the expectation is
  \[
    \E{}{X} =  \int_{-\infty}^{+\infty} x f(x) dx.
  \]
  In case it is discrete, let \(x_i\) be the values \(X\) can take, the expectation takes the form
  \[
    \E{}{X} =  \sum_{i} x_i p(x_i) dx.
  \]


Let \(g:\mathbb{R} \to \mathbb{R}\) be a measurable function, then \(g \circ X\)
is another random variable and we can talk about \(\E{}{g(X)}\), so in
case \(X\) is continuous, we have that
\[
\E{}{g(X)} =  \int_{-\infty}^{+\infty} g(x) f(x) dx.
\]
\end{definition}

In the above definition, the expectation is calculated over the probability distribution \(P\) of the random variable, in future sections this distribution is unknown and a guessed distribution \(Q\) will be used. In this cases when the distribution is not clear from the context the notation \(\E{Q}{X}\) will be used.

\begin{definition}
  We define the \(k^{th}\) moment of a distribution as the average of \(X^k\)
  over the distribution
  \[
    \mu_k = \E{}{X^k}
  \]
  For \(k = 1\) it is typically denoted as \(\mu\). Note \(\mu_{k}\) can also denote the \(k^{th}\) element in the mean vector of a multi-variate variable.
\end{definition}


\begin{definition}
  The \emph{variance} of a distribution is defined as
  \[
    Var(X) = \sigma^2 = \E{}{{(X - \E{}{X})}^2} = \E{}{X}^2 - \E{}{X^2}
  \]

  The positive square root of the variance \(\sigma\) is called the \emph{standard deviation}.
\end{definition}

When using a multi-variate distribution \(\bm{X} = {(X_1,\dots,X_N)}^T\) we can talk about the \emph{covariance
  matrix} \(\bSigma \) whose elements are

\[
\begin{aligned}
\bSigma_{ij} &= \E{}{\Big(X_i - \E{}{X_i}\Big)
  \Big(X_j - \E{}{X_j}\Big)} = \E{}{(X_i - \mu_i)(X_j - \mu_j)}\\
&=\E{}{X_i X_j}-\E{}{X_i}\E{}{X_j}
\end{aligned}
\]

The following result will be helpful later on.

\begin{proposition}\label{prop:expectation_over_marginal}
  Let \(\bX = \{X_1,\dots,X_N\}\) be a set of random variables,
  \(\bX_{0} \subset \bX\) and \(P(\bX), P(\bX_{0})\)
  their probability distributions.
  It follows that the expectation of a function \(g\) over \(\bX_0\), verifies
    \[
      \E{P(\bX)}{g(\bX_0)} = \E{P(\bX_0)}{g(\bX_0)}.
    \]
    That is, we only need to know the marginal distribution of the subset in
    order to carry out the average.
\end{proposition}

\begin{proof}
  Let \(\I = (i_{1}, \dots, i_{k})\) be the indexes corresponding to \(\bX_{0}\), then
  \[
    \begin{aligned}
      \E{P(\bX)}{g(\bX_{0})}&= \int_{x_{1}}\dots\int_{x_{N}}g(x_{i_{1}},\dots,x_{i_{k}})f(x_{1},\dots,x_{N}) \\
      &= \int_{x_{i_{1}}}\dots\int_{x_{i_{k}}} g(x_{i_{1}},\dots,x_{i_{k}}) \int \dots \int f(x_{1},\dots,x_{N}) d_{x_{1}},\dots,d_{x_{N}}\\
      &= \int_{x_{i_{1}}}\dots\int_{x_{i_{k}}} g(x_{i_{1}},\dots,x_{i_{k}}) f(x_{i_{1}},\dots,x_{i_{k}}) =  \E{P(\bX_{0})}{g(\bX_{0})}.\\
      \end{aligned}
  \]
Where in the last equality we used marginalization.
\end{proof}

We are going to discuss now some examples of probability distributions that are
going to be used from now on.

\section{Discrete distributions}

\subsection*{Bernoulli distribution}

The Bernoulli distribution describes a discrete binary variable \(X\) that takes
the value \(1\)  with probability \(p\) and the value \(0\)  with probability \(1-p\).
\[
  P(x) =
\left\{
  \begin{array}{ll}
    p  & \mbox{if } x = 1 \\
    1-p & \mbox{if } x = 0
  \end{array}.
\right.
\]

\subsection*{Categorical distribution}

A generalization of the Bernoulli distribution when the variable can take more than two states is the \emph{Categorical distribution}. Let \(Dom(X) = \{1,\dots,N\}\), then \(X\) follows a categorical distribution of parameters \(\theta = (\theta_{1},\dots, \theta_{N})\) if and only if
\[
  P(x \mid \theta) = \prod_{i=1}^{N}\theta_{i}^{\mathbb{I}[x = i]} \text{ and } \sum_{i = 1}^{N}\theta_{i} = 1.
\]

\subsection*{Binomial distribution}

The binomial distribution describes the number of successes in a sequence of
independent Bernoulli trials. A discrete binary random variable \(X\) follows a
\emph{binomial distribution} of parameters \(n \in \mathbb{N}\) and \(p \in
[0,1]\), denoted as \(X \sim B(n, p)\) if and only if
\[
  P(k) = \binom{n}{k}p^k{(1-p)}^{n-k}.
\]
That is, \(X\) models the probability of getting \(k\) times an \(1\) outcome in a Bernoulli trial with parameter \(p\) in \(n\) total trials.


\subsection*{Multinomial distribution}
The multinomial distribution is a generalization of the binomial distribution which describes the result of a sequence of independent trials in a categorical distribution. A discrete random variable \(X\) follows a \emph{multinomial distribution} of parameters \(n \in \mathbb{N}\), \(\bm{p} = (p_{1},\dots,p_{K})\) such that \(\sum p_{k} = 1\)  if and only if
\[
  P(x_{1},\dots,x_{K}) =
  \begin{cases}
    \frac{n!}{x_{1}!\dots x_{K}!}\prod_{k=1}^{K}p_{k}^{x_{k}} & \text{if } \sum_{k}{x_{k}} = n\\
    0 & \text{otherwise}
  \end{cases}
\]

\section{Continuous distributions}

\subsection*{Uni-Variate Gaussian distribution}

The \emph{normal} or \emph{Gaussian distribution} is a type of continuous
probability distribution for real-valued random variables.

\begin{definition}
  We say the real valued random variable \(X\) follows a \emph{normal distribution} of
  parameters \(\mu, \sigma \in \mathbb{R}\), denoted as \(X \sim \mathcal{N}(\mu,
  \sigma)\) if and only if, its probability density function exists and is
  \[
    f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2}\big(\frac{x-\mu}{\sigma} \big)^2}.
  \]

  The parameter \(\mu\) is the mean or expectation of the distribution and
  \(\sigma\) is its standard deviation.

\end{definition}

The simplest case of a normal distribution is known as \emph{standard normal
  distribution}. It is a special case where \(\mu = 0\) and \(\sigma = 1\), then
its density function is
\[
  f(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}.
\]

One of the properties of the normal distribution is that if \(X \sim \mathcal{N}(\mu, \sigma)\), \(a,b \in \mathbb{R}\) and \(f:\mathbb{R} \to \mathbb{R}\) be defined
as \(f(x) = ax + b\), then \(f(X) \sim \mathcal{N}(\mu + b, a^2 \sigma)\).

\subsection*{Multi-Variate Gaussian distribution}

This distribution plays a fundamental role in this project so we will discuss
its properties in more detail. It is an extension of the uni-variate one when having a
multi-variate random variable.

\begin{definition}
We say that a random vector \(\bm{X} = (X_1,\dots,X_N)\) follows a \emph{multi-variate normal or Gaussian distribution} of parameters \(\bm{\mu} \in \mathbb{R}^N\) and \(\bm{\Sigma}
\in \mathbb{M}_N(\mathbb{R})\), denoted as \(\bm{X} \sim \mathcal{N}(\bm{\mu},
\bm{\Sigma})\) if and only if its probability density function is

\[
  f(\bm{x}) = \frac{1}{\sqrt{det(2\pi \bm{\Sigma})}}e^{-\frac{1}{2}(\bm{x} - \bm{\mu})^T\bm{\Sigma}^{-1}(\bm{x}-\bm{\mu})} .
\]

Where \(\bm{\mu}\) is the mean vector of the distribution, and \(\bm{\Sigma}\)
the \emph{covariance matrix}. The inverse matrix \(\bm{\Sigma}^{-1}\) is called \emph{precision matrix}.
It also satisfies that
\[
\bm{\mu} = \mathbb{E}[\bm{X}], \quad \bSigma = \E{}{(\bx - \bmu)(\bx - \bmu)^T}.
\]

As \(\bSigma\) is a real symmetric matrix, it can be eigen-decomposed as
\[
  \bSigma = \bm{E}\bm{\Delta}\bm{E}^T,
\]
where \(\bm{E}^T\bm{E} = \bm{I}\) and \(\bm{\Delta} =
diag(\lambda_1,\dots,\lambda_n)\).

Using the transformation
\[
  \bm{y} = \bm{\Delta}^{\frac{1}{2}}\bm{E}^T(\bx - \bmu),
\]
we get that

\[
  (\bx - \bmu)^T\bSigma(\bx - \bmu) = \bm{y}^T\bm{y}.
\]

Using this, the multi-variate Gaussian distribution reduces to a product of \(n\)
uni-variate standard Gaussian distributions.

\end{definition}

\subsection*{Gamma distribution}

\begin{definition}

We say that a continuous random variable \(X\) defined on \(\mathbb{R}^{+}\)  follows a \emph{gamma distribution} of parameters \(\alpha, \beta > 0\), denoted as \(X \sim Gamma(\alpha, \beta)\) if and only if its density function is

\[
  f(x) = \frac{\beta^{\alpha} x^{\alpha-1}e^{-\beta x}}{\Gamma(\alpha)},
\]
where \(\Gamma\) is the Gamma function defined as
\[
  \Gamma(\alpha) = \int_{0}^{\infty}x^{\alpha-1}e^{-x} dx.
\]
\end{definition}

The mean is given by \(\E{}{X} = \frac{\alpha}{\beta}\).

\begin{definition}
The \emph{inverse gamma distribution} is defined by the density function
\[
  f(x) =  \frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{-\alpha-1}e^{-\beta/x}.
\]
\end{definition}

\subsection*{Wishart distribution}

The Wishart distribution is a generalization of the gamma distribution to multiple dimensions. Consider \(G\) a \(p\times \nu\) matrix where each column \(G_{i} \sim \mathcal{N}_{p}(0, \bV)\) is independent from the others, with \(V\) a common vector.

Then \(S = GG^{T}\) follows a Wishart distribution with \(\nu\) degrees of freedom,
\[
  S \sim \mathcal{W}(\nu, \bV).
\]
The Wishart distribution is characterized by its probability density function
\[
  f(x) = \frac{1}{2^{\nu p/2} |\bV|^{\nu /2} \Gamma_{p}(\frac{\nu}{2})}|x|^{(\nu-p-1)/2}e^{-(1/2)tr(\bV^{-1}x)},
\]
where
\[
  \Gamma_{p}(\frac{\nu}{2}) = \pi^{p(p-1)/4}\prod_{j=1}^{p}\Gamma \Big( \frac{n}{2}-\frac{j-1}{2} \Big).
\]

\subsection*{Gaussian-Wishart distribution}

The Gaussian-Wishart distribution is a four parameter distribution. Let \(\bmu\) follow a Gaussian distribution of mean \(\bmu_{0}\) and covariance matrix \((\bm{\lambda} \bLambda)^{-1}\)
\[
  \bmu \sim \mathcal{N}(\bmu_{0}, (\bm{\lambda} \bLambda)^{-1}),
\]
where \(\bLambda\) follows a Wishart distribution with parameters \(\nu, \bm{W}\):
\[
  \bLambda \sim \mathcal{W}(\nu, \bm{W}).
\]
Then their joint distribution is a Gaussian-Wishart distribution:
\[
  (\bmu, \bLambda) \sim \mathcal{N}\mathcal{W}(\bmu_{0}, \bm{\lambda}, \nu, \bm{W}).
\]
Their probability density function equals a product of the corresponding Gaussian and Wishart distribution:
\[
  f(\bmu, \bLambda) = \mathcal{N}(\bmu_{0}, (\bm{\lambda} \bLambda)^{-1})\mathcal{W}(\nu, \bm{W})\footnote{Each distribution symbolize its density function.}.
\]

\subsection*{Beta distribution}

\begin{definition}
We say that a continuous random variable \(X\) defined on the
interval \([0,1]\) follows a \emph{Beta distribution} of parameters \(\alpha,
\beta > 0\), denoted as \(X \sim Beta(\alpha, \beta)\) if and only if its
density function is

\[
  f(x) = \frac{1}{B(\alpha, \beta)}x^{\alpha - 1}(1-x)^{\beta -1},
\]
where \(B(\alpha, \beta)\) is the \emph{beta function} defined as
\[
  B(\alpha, \beta) = \int_0^1 x^{\alpha - 1}(1-x)^{\beta -1} dx.
\]
\end{definition}

Its mean is given by \(\E{}{X} = \frac{\alpha}{\alpha + \beta}\).

\subsection*{Dirichlet distribution}

The Dirichlet distribution is a family of continuous multi-variate probability
distributions parameterized by a vector \(\bm{\alpha}\) of positive reals. It is
a multi-variate generalization of the Beta distribution.

\begin{definition}
  We say that a continuous random multi-variate variable \(\bX\) with order
  \(K \geq 2\), follows a \emph{Dirichlet
    distribution} with parameters \(\bm{\alpha} = (\alpha_{1}, \dots, \alpha_{K})\), if and
  only if its density function is defined as
  \[
    f(\bx) = \frac{1}{B(\bm{\alpha})}\prod_{k = 1}^{K}x_{k}^{\alpha_{k}-1},
  \]
  and it satisfies that
  \[
    \sum_{k=1}^{K} x_{k} = 1 \text{ and } x_{k} > 0 \ \forall k=1,\dots,K.
  \]
\end{definition}

Where the normalization constant is the multi-variate beta function
\[
  B(\bm{\alpha}) = \frac{\prod_{k} \Gamma (\alpha_{k})}{\Gamma \big( \sum_{k}\alpha_{k} \big)}.
\]

When the vector parameter \(\bm{\alpha}\) is filled with the same value \(\alpha_{0}\), the distribution is called Symmetric-Dirichlet with parameter \(\alpha_{0}\).

\begin{proposition}\label{prop:dirichlet_marginal}
  Let
  \((X_{0},\dots, X_{n}) \sim \text{Dirichlet}(\alpha_{0}, \dots, \alpha_{n})\),
  then \(X_{0} \sim \text{Beta}(\alpha_{0}, \alpha_{1}+\dots +\alpha_{n})\).
\end{proposition}
\begin{proof}
  Following~\cite{farrow}, we can write the joint probability as
  \[
    f(x_{1},\dots,x_{n}) = f_{1}(x_{1})f_{2}(x_{2}\mid x_{1})\dots f_{n-1}(x_{n-1}\mid x_{1},\dots, x_{n-2}).
  \]
  We do not need the last term because it is fixed given the others. In fact, let \(A = \sum_{i} \alpha_{i}\), we can write it as
  \[
   \Bigg( \frac{\Gamma(A)}{\Gamma(\alpha_{1}) \Gamma(A - \alpha_{1})}x_{1}^{\alpha_{1}-1}(1 - x_{1})^{A - \alpha_{1} -1}\Bigg)\Bigg( \frac{\Gamma(A - \alpha_{1})}{\Gamma(\alpha_{2}) \Gamma(A - \alpha_{1} - \alpha_{2})}\frac{ x_{2}^{\alpha_{2}-1}(1-x_{1}- x_{2})^{A - \alpha_{2}- \alpha_{1} - 1} }{(1-\alpha_{1})^{A - \alpha_{1} - 1} }\Bigg )
 \]
 \[
   \dots \Big(\frac{\Gamma(A - \alpha_{1} - \dots - \alpha_{n-2})}{\Gamma(\alpha_{n-1}) \Gamma(A - \alpha_{1}- \dots - \alpha_{n-1})}  \frac{ x_{n-1}^{\alpha_{n}-1} x_{n}^{\alpha_{n}-1}}{(1-x_{1}- \dots - x_{n-2})^{\alpha_{n-1}+\alpha_{n}-1}}\Big).
 \]

 From this, we get that
 \[
   f_{1}(x_{1}) =  \frac{\Gamma(A)}{\Gamma(\alpha_{1}) \Gamma(A - \alpha_{1})}x_{1}^{\alpha_{1}-1}(1 - x_{1})^{A - \alpha_{1} -1} \implies X_{1} \sim \text{Beta}(\alpha_{1}, A- \alpha_{1}).
 \]

 Making the decomposition over any other \(X_{j}\), results on
 \(X_{j} \sim \text{Beta}(\alpha_{j}, A - \alpha_{j})\).
\end{proof}



\section{Kullback-Leibler divergence}

\begin{definition}
  Let \(P\) and \(Q\) be two probability distributions over the same probability space \( \Omega \), the \emph{Kullback-Leibler divergence}
  \(\KL{Q}{P}\) measures the ``difference'' between both distributions as
  \[
    \KL{Q}{P} = \E{Q}{\log Q(x) - \log P(x)}.
  \]

  The Kullback-Leibler divergence is defined if and only if for all \( x \in \Omega \) such that \( P(x) = 0 \), then \( Q(x) = 0 \). In measure terms, \( Q \) is absolutely continuous with respect to \( P \).
\end{definition}

\begin{proposition}
The Kullback-Leibler divergence is always non-negative.
\end{proposition}
\begin{proof}
  As the logarithm is bounded by \(x - 1\), we can bound \(\log{\frac{P(x)}{Q(x)}}\)
  \[
    \log{x} \leq x - 1 \implies \frac{P(x)}{Q(x)} - 1 \geq \log{\frac{P(x)}{Q(x)}}.
  \]

  Since probabilities are non-negative, we can multiply by \(Q(x)\) in the last inequality
  \[
    P(x) - Q(x) \geq Q(x) \log \frac{P(x)}{Q(x)} = Q(x) \log{P(x)} - Q(x) \log{Q(x)}.
  \]
  Now we integrate (sum in case of discrete variables) both sides

  \[
    0 \geq \E{Q}{\log{P(x)} - \log{Q(x)}} \implies \E{Q}{\log{Q(x)}
    - \log{P(x)}} \geq 0.
  \]
\end{proof}
As a result, the Kullback-Leibler divergence is \(0\) if and only if the two
distributions are equal almost everywhere.
