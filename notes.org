#+TITLE:  Statistical Models with Variational Methods
#+SUBTITLE:End-of-degree project
#+LANGUAGE: en
#+AUTHOR: Luis Antonio Ortega Andr√©s @@latex: \\@@76425628D @@latex: \\@@ ludvins@correo.ugr.es
#+OPTIONS: toc:t num:2

#+latex_class_options: [oneside,openright,titlepage,numbers=noenddot,openany,headinclude,footinclude=true,cleardoublepage=empty,abstractoff,BCOR=5mm,paper=a4,fontsize=12pt,ngerman,american]
#+latex_header_extra: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[AUTO]{babel}
#+latex_header_extra: \usepackage{minted}
#+latex_header_extra: \usepackage[beramono,eulerchapternumbers,linedheaders,parts,a5paper,dottedtoc,manychapters]{classicthesis}

#+latex_header: \usepackage{tikz}
#+latex_header: \usetikzlibrary{positioning,shapes,arrows}
#+latex_header: \usepackage{dcolumn}
#+latex_header: \usepackage{booktabs}

#+latex_header_extra: \input{setup}
#+latex_header_extra: \input{classicthesis-config}
#+latex_header: \input{macros}
\clearpage


* Probability

** Notation

Variables will be denoted with lower case $x$ and a set of variables with a
calligraphic symbol like $\mathcal{V}$.

The meaning of $p(state)$ will be clear without a reference to the variable.
Otherwise $p(x = state)$ will be used. \\

We will denote $p(x)$ the probability of $x$ taking a specific value, this means
that
$$\int_x f(x) = \int_{dom(x)}f(x=s) ds$$

** Definitions


We will define some concepts from a given joint distribution $p(x,y)$, this is,
the probability of two events.\\

#+begin_definition
A *marginal* $p(x)$ of the joint distribution is the
distribution of a single variable given by
$$
p(x) = \sum_y p(x,y) \hspace{2cm} p(x) = \int_y p(x,y)
$$
#+end_definition

We can undestand this as the probability of an event irrespective of the outcome
of another variable.


#+begin_definition
The *conditional probability* of $x$ given $y$ is defined as
$$
p(x|y) = \frac{p(x,y)}{p(y)}
$$

If $p(y) = 0$ then it is not defined.
#+end_definition
This formula is also known as *Bayes' rule*. With this definition the
conditional probability is the probability of one event occurring in the presence of a
second event. \\

Now suppose we have some observed data $\mathcal{D}$ and we want to learn about
a set of parameters \theta. Using Bayes' rule we got that

$$
p(\theta|\mathcal{D}) = \frac{p(\mathcal{D}|\theta)p(\theta)}{p(\mathcal{D})} =
\frac{p(\mathcal{D}|\theta)p(\theta)}{ \int_{\theta} p(\mathcal{D}|\theta)p(\theta)}
$$

This shows how from a /generative model/ $p(\mathcal{D}|\theta)$ of the dataset
and a /prior/ belief $p(\theta)$, we can infer the /posterior/ distribution
$p(\theta|\mathcal{D})$. \\

#+begin_exampleth
Consider a study where the relation of a disease $D$ and an habit $H$
is being investigated. Consider $p(D)=10^{-5}$, $p(H)=0.5$ and $p(H|D) = 0.9$. What is the
probability that a person with habit $H$ will have disease $D$?

$$
p(D|S) = \frac{p(D,H)}{p(D)} = \frac{p(H|D)p(D)}{p(H)} =
\frac{ 0.9 \times 10^{-5}}{ 0.5 } = 1.8 \times 10^{-5}
$$

If we set the probability of having habit $H$ to a much lower value as $p(H) =
0.001$, then the above calculation gives aproximately $1/100$.\\

Intuitively, a smaller number of people have the habit and most of them have the
desease. This means that the relation between having the desease and the habit
is stronger.
#+end_exampleth

* Graphical Models


#+BEGIN_latex
\begin{tikzpicture}[
  node distance=1cm and 0cm,
  mynode/.style={draw,ellipse,text width=2cm,align=center}
]
\node[mynode] (sp) {Sprinkler};
\node[mynode,below right=of sp] (gw) {Grass wet};
\node[mynode,above right=of gw] (ra) {Rain};
\path (ra) edge[-latex] (sp)
(sp) edge[-latex] (gw)
(gw) edge[latex-] (ra);
\node[left=0.5cm of sp]
{
\begin{tabular}{cM{2}M{2}}
\toprule
& \multicolumn{2}{c}{Sprinkler} \\
Rain & \multicolumn{1}{c}{T} & \multicolumn{1}{c}{F} \\
\cmidrule(r){1-1}\cmidrule(l){2-3}
F & 0.4 & 0.6 \\
T & 0.01 & 0.99 \\
\bottomrule
\end{tabular}
};
\node[right=0.5cm of ra]
{
\begin{tabular}{M{1}M{1}}
\toprule
\multicolumn{2}{c}{Sprinkler} \\
\multicolumn{1}{c}{T} & \multicolumn{1}{c}{F} \\
\cmidrule{1-2}
0.2 & 0.8 \\
\bottomrule
\end{tabular}
};
\node[below=0.5cm of gw]
{
\begin{tabular}{ccM{2}M{2}}
\toprule
& & \multicolumn{2}{c}{Grass wet} \\
\multicolumn{2}{l}{Sprinkler rain} & \multicolumn{1}{c}{T} & \multicolumn{1}{c}{F} \\
\cmidrule(r){1-2}\cmidrule(l){3-4}
F & F & 0.4 & 0.6 \\
F & T & 0.01 & 0.99 \\
T & F & 0.01 & 0.99 \\
T & T & 0.01 & 0.99 \\
\bottomrule
\end{tabular}
};

\end{tikzpicture}
#+END_latex
